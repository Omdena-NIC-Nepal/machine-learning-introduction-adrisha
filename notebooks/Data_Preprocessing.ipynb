{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " crim       0\n",
      "zn         0\n",
      "indus      0\n",
      "chas       0\n",
      "nox        0\n",
      "rm         0\n",
      "age        0\n",
      "dis        0\n",
      "rad        0\n",
      "tax        0\n",
      "ptratio    0\n",
      "b          0\n",
      "lstat      0\n",
      "medv       0\n",
      "dtype: int64\n",
      "There are no missing values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/bostonhousing.csv')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Check if there are any missing values in the entire dataset\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"There are no missing values in the dataset.\")\n",
    "else:\n",
    "    print(\"There are missing values in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "Since the Boston Housing Dataset typically does not have missing values, we'll assume there are no missing values to handle. However, if there were missing values, you could handle them using methods like imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values to handle.\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "if missing_values.sum() > 0:\n",
    "    \n",
    "    # Example: Fill missing values with the mean of the column\n",
    "    data.fillna(data.mean(), inplace=True)\n",
    "    print(\"Missing values have been filled with the mean of each column.\")\n",
    "else:\n",
    "    print(\"No missing values to handle.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Outliers\n",
    "Let's identify outliers using the Interquartile Range (IQR) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in crim: 66\n",
      "Number of outliers in zn: 68\n",
      "Number of outliers in indus: 0\n",
      "Number of outliers in chas: 35\n",
      "Number of outliers in nox: 0\n",
      "Number of outliers in rm: 30\n",
      "Number of outliers in age: 0\n",
      "Number of outliers in dis: 5\n",
      "Number of outliers in rad: 0\n",
      "Number of outliers in tax: 0\n",
      "Number of outliers in ptratio: 15\n",
      "Number of outliers in b: 77\n",
      "Number of outliers in lstat: 7\n",
      "Number of outliers in medv: 40\n"
     ]
    }
   ],
   "source": [
    "# List of features to check for outliers\n",
    "features = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat', 'medv']\n",
    "\n",
    "# Function to identify outliers using IQR\n",
    "def identify_outliers(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "# Identify outliers for each feature\n",
    "outliers_info = {}\n",
    "for feature in features:\n",
    "    outliers = identify_outliers(data, feature)\n",
    "    outliers_info[feature] = outliers\n",
    "    print(f\"Number of outliers in {feature}: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Outliers\n",
    "To handle outliers, we can choose to remove them or cap them. Here, we'll remove outliers based on the IQR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers have been removed from the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Function to remove outliers using IQR\n",
    "def remove_outliers(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    filtered_data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "    return filtered_data\n",
    "\n",
    "# Remove outliers for each feature\n",
    "for feature in features:\n",
    "    data = remove_outliers(data, feature)\n",
    "\n",
    "print(\"Outliers have been removed from the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas for One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "5  0.02985   0.0   2.18     0  0.458  6.430  58.7  6.0622    3  222     18.7   \n",
      "6  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311     15.2   \n",
      "7  0.14455  12.5   7.87     0  0.524  6.172  96.1  5.9505    5  311     15.2   \n",
      "\n",
      "        b  lstat  medv  \n",
      "0  396.90   4.98  24.0  \n",
      "1  396.90   9.14  21.6  \n",
      "5  394.12   5.21  28.7  \n",
      "6  395.60  12.43  22.9  \n",
      "7  396.90  19.15  27.1  \n"
     ]
    }
   ],
   "source": [
    "# Adding a new categorical variable 'neighborhood'\n",
    "data['neighborhood'] = ['A' if i < 250 else 'B' for i in range(len(data))]\n",
    "\n",
    "# One-Hot Encoding using pandas\n",
    "data_encoded = pd.get_dummies(data, columns=['neighborhood'], drop_first=True)\n",
    "\n",
    "print(data_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Scikit-Learn for Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       crim    zn     indus  chas       nox        rm       age       dis  \\\n",
      "0  0.000000  0.18  0.067815     0  0.314815  0.577505  0.641607  0.269203   \n",
      "1  0.000236  0.00  0.242302     0  0.172840  0.547998  0.782698  0.348962   \n",
      "2  0.000236  0.00  0.242302     0  0.172840  0.694386  0.599382  0.348962   \n",
      "3  0.000293  0.00  0.063050     0  0.150206  0.658555  0.441813  0.448545   \n",
      "4  0.000705  0.00  0.063050     0  0.150206  0.687105  0.528321  0.448545   \n",
      "\n",
      "        rad       tax   ptratio         b     lstat  medv neighborhood  \\\n",
      "0  0.000000  0.208015  0.287234  1.000000  0.089680  24.0            A   \n",
      "1  0.043478  0.104962  0.553191  1.000000  0.204470  21.6            A   \n",
      "2  0.043478  0.104962  0.553191  0.989737  0.063466  34.7            A   \n",
      "3  0.086957  0.066794  0.648936  0.994276  0.033389  33.4            A   \n",
      "4  0.086957  0.066794  0.648936  1.000000  0.099338  36.2            A   \n",
      "\n",
      "   neighborhood_encoded  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n"
     ]
    }
   ],
   "source": [
    "# Adding a new categorical variable 'neighborhood'\n",
    "data['neighborhood'] = ['A' if i < 250 else 'B' for i in range(len(data))]\n",
    "\n",
    "# Label Encoding using scikit-learn\n",
    "label_encoder = LabelEncoder()\n",
    "data['neighborhood_encoded'] = label_encoder.fit_transform(data['neighborhood'])\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Data:\n",
      "       crim    zn     indus       nox        rm       age       dis       rad  \\\n",
      "0  0.000000  0.18  0.067815  0.314815  0.577505  0.641607  0.269203  0.000000   \n",
      "1  0.000236  0.00  0.242302  0.172840  0.547998  0.782698  0.348962  0.043478   \n",
      "2  0.000236  0.00  0.242302  0.172840  0.694386  0.599382  0.348962  0.043478   \n",
      "3  0.000293  0.00  0.063050  0.150206  0.658555  0.441813  0.448545  0.086957   \n",
      "4  0.000705  0.00  0.063050  0.150206  0.687105  0.528321  0.448545  0.086957   \n",
      "\n",
      "        tax   ptratio         b     lstat  \n",
      "0  0.208015  0.287234  1.000000  0.089680  \n",
      "1  0.104962  0.553191  1.000000  0.204470  \n",
      "2  0.104962  0.553191  0.989737  0.063466  \n",
      "3  0.066794  0.648936  0.994276  0.033389  \n",
      "4  0.066794  0.648936  1.000000  0.099338  \n"
     ]
    }
   ],
   "source": [
    "# List of numerical features\n",
    "numerical_features = ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the numerical features\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "print(\"Normalized Data:\")\n",
    "print(data[numerical_features].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Data:\n",
      "       crim        zn     indus       nox        rm       age       dis  \\\n",
      "0 -0.419782  0.284830 -1.287909 -0.144217  0.413672 -0.120013  0.140214   \n",
      "1 -0.417339 -0.487722 -0.593381 -0.740262  0.194274  0.367166  0.557160   \n",
      "2 -0.417342 -0.487722 -0.593381 -0.740262  1.282714 -0.265812  0.557160   \n",
      "3 -0.416750 -0.487722 -1.306878 -0.835284  1.016303 -0.809889  1.077737   \n",
      "4 -0.412482 -0.487722 -1.306878 -0.835284  1.228577 -0.511180  1.077737   \n",
      "\n",
      "        rad       tax   ptratio         b     lstat  \n",
      "0 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
      "1 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
      "2 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
      "3 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
      "4 -0.752922 -1.106115  0.113032  0.441052 -1.026501  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the numerical features\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "print(\"Standardized Data:\")\n",
    "print(data[numerical_features].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shapes:\n",
      "X_train: (404, 12)\n",
      "y_train: (404,)\n",
      "\n",
      "Testing set shapes:\n",
      "X_test: (102, 12)\n",
      "y_test: (102,)\n"
     ]
    }
   ],
   "source": [
    "# List of numerical features\n",
    "numerical_features = ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']\n",
    "\n",
    "# Target variable\n",
    "target = 'medv'\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data[numerical_features]\n",
    "y = data[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training set shapes:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "\n",
    "print(\"\\nTesting set shapes:\")\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
