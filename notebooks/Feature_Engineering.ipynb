{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ...  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296  ...   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242  ...   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242  ...   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222  ...   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222  ...   \n",
      "\n",
      "        b  lstat  medv    rm_age  tax_ptratio  rm_squared  age_squared  \\\n",
      "0  396.90   4.98  24.0  428.6900       4528.8   43.230625      4251.04   \n",
      "1  396.90   9.14  21.6  506.6169       4307.6   41.229241      6225.21   \n",
      "2  392.83   4.03  34.7  439.0035       4307.6   51.624225      3733.21   \n",
      "3  394.63   2.94  33.4  320.5084       4151.4   48.972004      2097.64   \n",
      "4  396.90   5.33  36.2  387.3674       4151.4   51.079609      2937.64   \n",
      "\n",
      "   house_age  total_rooms  age_bin  \n",
      "0     1957.8     100.5975        4  \n",
      "1     1944.1     114.2938        4  \n",
      "2     1961.9     127.8930        4  \n",
      "3     1977.2     130.8626        3  \n",
      "4     1968.8     133.6489        3  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/bostonhousing.csv')\n",
    "\n",
    "# List of numerical features\n",
    "numerical_features = ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']\n",
    "\n",
    "# Target variable\n",
    "target = 'medv'\n",
    "\n",
    "# Create interaction terms\n",
    "data['rm_age'] = data['rm'] * data['age']\n",
    "data['tax_ptratio'] = data['tax'] * data['ptratio']\n",
    "\n",
    "# Create polynomial features\n",
    "data['rm_squared'] = data['rm'] ** 2\n",
    "data['age_squared'] = data['age'] ** 2\n",
    "\n",
    "# Create domain-specific features\n",
    "data['house_age'] = 2023 - data['age']  # Assuming the data is from 2023\n",
    "\n",
    "# Create aggregated features\n",
    "data['total_rooms'] = data['rm'] * data['ptratio']\n",
    "\n",
    "# Create bins for age\n",
    "data['age_bin'] = pd.cut(data['age'], bins=[0, 20, 40, 60, 80, 100], labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Print the first few rows of the dataset with new features\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical features\n",
    "numerical_features = ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']\n",
    "\n",
    "# Define different feature combinations\n",
    "feature_combinations = [\n",
    "    numerical_features,  # All features\n",
    "    ['rm', 'lstat', 'ptratio'],  # Selected features\n",
    "    ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio'],  # Excluding 'b' and 'lstat'\n",
    "    ['rm', 'lstat'],  # Minimal features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']\n",
      "Mean Squared Error: 24.635394156374495\n",
      "R-squared: 0.6640648675861113\n",
      "--------------------------------------------------\n",
      "Features: ['rm', 'lstat', 'ptratio']\n",
      "Mean Squared Error: 27.114957415580577\n",
      "R-squared: 0.6302528487272827\n",
      "--------------------------------------------------\n",
      "Features: ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio']\n",
      "Mean Squared Error: 28.502943852955298\n",
      "R-squared: 0.6113258770430279\n",
      "--------------------------------------------------\n",
      "Features: ['rm', 'lstat']\n",
      "Mean Squared Error: 31.243290601783627\n",
      "R-squared: 0.5739577415025858\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2\n",
    "\n",
    "# Target variable\n",
    "target = 'medv'\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "y = data[target]\n",
    "\n",
    "# Test different feature combinations\n",
    "results = []\n",
    "for features in feature_combinations:\n",
    "    X = data[features]\n",
    "    mse, r2 = train_and_evaluate(X, y)\n",
    "    results.append((features, mse, r2))\n",
    "\n",
    "# Print the results\n",
    "for features, mse, r2 in results:\n",
    "    print(f\"Features: {features}\")\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m features \u001b[38;5;129;01min\u001b[39;00m feature_combinations:\n\u001b[32m     40\u001b[39m     X = data[features]\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     mse, r2 = \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     results.append((features, mse, r2))\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mtrain_and_evaluate\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m     18\u001b[39m model = LinearRegression()\n\u001b[32m     19\u001b[39m model.fit(X_train, y_train)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m y_pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m mse = mean_squared_error(y_test, y_pred)\n\u001b[32m     22\u001b[39m r2 = r2_score(y_test, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NIC/Adrisha/Week 11/Machine_Learning/machine-learning-introduction-adrisha/.venv/lib/python3.13/site-packages/sklearn/linear_model/_base.py:297\u001b[39m, in \u001b[36mLinearModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    284\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03m    Predict using the linear model.\u001b[39;00m\n\u001b[32m    286\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m \u001b[33;03m        Returns predicted values.\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NIC/Adrisha/Week 11/Machine_Learning/machine-learning-introduction-adrisha/.venv/lib/python3.13/site-packages/sklearn/linear_model/_base.py:279\u001b[39m, in \u001b[36mLinearModel._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    277\u001b[39m coef_ = \u001b[38;5;28mself\u001b[39m.coef_\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m coef_.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_\u001b[49m + \u001b[38;5;28mself\u001b[39m.intercept_\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X @ coef_.T + \u001b[38;5;28mself\u001b[39m.intercept_\n",
      "\u001b[31mTypeError\u001b[39m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load Boston Housing Dataset\n",
    "boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
    "data = boston.frame\n",
    "\n",
    "# Rename target variable for consistency\n",
    "data.rename(columns={\"MEDV\": \"medv\"}, inplace=True)\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2\n",
    "\n",
    "# Define Target Variable\n",
    "target = \"medv\"\n",
    "y = data[target]\n",
    "\n",
    "# Define Different Feature Combinations to Test\n",
    "feature_combinations = [\n",
    "    [\"RM\", \"LSTAT\"],  # Two highly correlated features\n",
    "    [\"RM\", \"LSTAT\", \"PTRATIO\"],  # Adding pupil-teacher ratio\n",
    "    [\"CRIM\", \"ZN\", \"INDUS\", \"NOX\"],  # Less relevant features\n",
    "    data.columns.drop(\"medv\").tolist()  # All features except target\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "for features in feature_combinations:\n",
    "    X = data[features]\n",
    "    mse, r2 = train_and_evaluate(X, y)\n",
    "    results.append((features, mse, r2))\n",
    "\n",
    "# Print the results\n",
    "for features, mse, r2 in results:\n",
    "    print(f\"Features: {features}\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"R-squared: {r2:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['RM', 'LSTAT']\n",
      "Mean Squared Error: 31.24\n",
      "R-squared: 0.5740\n",
      "--------------------------------------------------\n",
      "Features: ['RM', 'LSTAT', 'PTRATIO']\n",
      "Mean Squared Error: 27.11\n",
      "R-squared: 0.6303\n",
      "--------------------------------------------------\n",
      "Features: ['CRIM', 'ZN', 'INDUS', 'NOX']\n",
      "Mean Squared Error: 46.40\n",
      "R-squared: 0.3673\n",
      "--------------------------------------------------\n",
      "Features: ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
      "Mean Squared Error: 24.29\n",
      "R-squared: 0.6688\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load Boston Housing Dataset\n",
    "boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
    "data = boston.frame\n",
    "\n",
    "# Rename target variable for consistency\n",
    "data.rename(columns={\"MEDV\": \"medv\"}, inplace=True)\n",
    "\n",
    "# Convert all columns to numeric\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2\n",
    "\n",
    "# Define Target Variable\n",
    "target = \"medv\"\n",
    "y = np.array(data[target], dtype=float)  # Convert to NumPy array\n",
    "\n",
    "# Define Different Feature Combinations to Test\n",
    "feature_combinations = [\n",
    "    [\"RM\", \"LSTAT\"],\n",
    "    [\"RM\", \"LSTAT\", \"PTRATIO\"],\n",
    "    [\"CRIM\", \"ZN\", \"INDUS\", \"NOX\"],\n",
    "    data.columns.drop(\"medv\").tolist()  # All features except target\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "for features in feature_combinations:\n",
    "    X = np.array(data[features], dtype=float)  # Ensure numerical format\n",
    "    mse, r2 = train_and_evaluate(X, y)\n",
    "    results.append((features, mse, r2))\n",
    "\n",
    "# Print the results\n",
    "for features, mse, r2 in results:\n",
    "    print(f\"Features: {features}\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"R-squared: {r2:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features - Mean Squared Error:  24.291119474973478\n",
      "Original Features - R-squared:  0.6687594935356326\n",
      "New Features - Mean Squared Error:  14.100986861390178\n",
      "New Features - R-squared:  0.807714995003565\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/bostonhousing.csv')\n",
    "\n",
    "# Original features\n",
    "original_features = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']\n",
    "\n",
    "# Create new features\n",
    "data['rm_age'] = data['rm'] * data['age']\n",
    "data['tax_ptratio'] = data['tax'] * data['ptratio']\n",
    "data['rm_squared'] = data['rm'] ** 2\n",
    "data['age_squared'] = data['age'] ** 2\n",
    "data['house_age'] = 2023 - data['age']  # Assuming the data is from 2023\n",
    "data['total_rooms'] = data['rm'] * data['ptratio']\n",
    "data['age_bin'] = pd.cut(data['age'], bins=[0, 20, 40, 60, 80, 100], labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# New features (including original features and additional features)\n",
    "new_features = original_features + ['rm_age', 'tax_ptratio', 'rm_squared', 'age_squared', 'house_age', 'total_rooms', 'age_bin']\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2\n",
    "\n",
    "# Target variable\n",
    "target = 'medv'\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "y = data[target]\n",
    "\n",
    "# Train and evaluate the model with original features\n",
    "X_original = data[original_features]\n",
    "mse_original, r2_original = train_and_evaluate(X_original, y)\n",
    "\n",
    "# Train and evaluate the model with new features\n",
    "X_new = data[new_features]\n",
    "mse_new, r2_new = train_and_evaluate(X_new, y)\n",
    "\n",
    "# Print the results\n",
    "print(\"Original Features - Mean Squared Error: \", mse_original)\n",
    "print(\"Original Features - R-squared: \", r2_original)\n",
    "print(\"New Features - Mean Squared Error: \", mse_new)\n",
    "print(\"New Features - R-squared: \", r2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
